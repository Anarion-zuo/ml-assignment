{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineModel(nn.Module):\n",
    "    def __init__(self, device, feature_count, hidden_count, output_count):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(feature_count, hidden_count, device=device),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_count, output_count, device=device),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "    \n",
    "    def forward(self, features, targets):\n",
    "        b, t = features.size()\n",
    "        logits = self.model(features)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.train = df.drop(['quality'], axis=1)\n",
    "        self.target = df['quality']\n",
    "        print(self.target.shape, self.train.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.train)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # make an onehot vector\n",
    "        target = self.target.iloc[index]\n",
    "        result = [0] * 11\n",
    "        result[target] = 1\n",
    "        return torch.tensor(data=self.train.iloc[index, :].to_numpy(), dtype=torch.float), torch.tensor(data=result, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_red = pd.read_csv('data/red_processed.csv')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(train_red, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1071,) (1071, 11)\n",
      "(528,) (528, 11)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = WineDataset(train_df)\n",
    "test_dataset = WineDataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainerConfig:\n",
    "    lr = 8e-3\n",
    "    batch_size = 64\n",
    "    num_workers = 6\n",
    "    max_epochs = 1000\n",
    "    \n",
    "trainer_config = TrainerConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_dataset, test_dataset, config, device):\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        self.model = model\n",
    "        self.train_dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        \n",
    "    def train(self):\n",
    "        config = self.config\n",
    "        model = self.model\n",
    "        optimizer = optim.AdamW(self.model.parameters(), lr=config.lr)\n",
    "        \n",
    "        def run_epoch(split):\n",
    "            is_train = split == 'train'\n",
    "            model.train(is_train)\n",
    "            data = self.train_dataset if is_train else self.test_dataset\n",
    "            loader = DataLoader(data, batch_size=config.batch_size, num_workers=config.num_workers)\n",
    "\n",
    "            losses = []\n",
    "            pbar = tqdm(enumerate(loader), total=len(loader)) if is_train else enumerate(loader)\n",
    "            for it, (x, y) in pbar:\n",
    "\n",
    "                # place data on the correct device\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "\n",
    "                # forward the model\n",
    "                with torch.set_grad_enabled(is_train):\n",
    "                    logits, loss = model(x, y)\n",
    "                    loss = loss.mean() # collapse all losses if they are scattered on multiple gpus\n",
    "                    losses.append(loss.item())\n",
    "\n",
    "                if is_train:\n",
    "\n",
    "                    # backprop and update the parameters\n",
    "                    model.zero_grad()\n",
    "                    loss.backward()\n",
    "                    # torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_norm_clip)\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # report progress\n",
    "                    pbar.set_description(f\"epoch {epoch+1} iter {it}: train loss {loss.item():.5f}. lr {self.config.lr:e}\")\n",
    "\n",
    "            if not is_train:\n",
    "                logger.info(\"test loss: %f\", np.mean(losses))\n",
    "        \n",
    "        for epoch in range(config.max_epochs):\n",
    "            run_epoch('train')\n",
    "            if self.test_dataset is not None:\n",
    "                run_epoch('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'\n",
    "model = WineModel(device, 11, 4, 11)\n",
    "trainer = Trainer(model, train_dataset, None, trainer_config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]/home/anarion/anaconda3/envs/local_nmt/lib/python3.8/site-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "epoch 1 iter 16: train loss 2.00315. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 164.71it/s]\n",
      "epoch 2 iter 16: train loss 1.99283. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.62it/s]\n",
      "epoch 3 iter 16: train loss 1.99179. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 121.41it/s]\n",
      "epoch 4 iter 16: train loss 1.99159. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 138.25it/s]\n",
      "epoch 5 iter 16: train loss 1.99166. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 152.07it/s]\n",
      "epoch 6 iter 16: train loss 1.99203. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 129.91it/s]\n",
      "epoch 7 iter 16: train loss 1.99351. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.14it/s]\n",
      "epoch 8 iter 16: train loss 2.00291. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 141.55it/s]\n",
      "epoch 9 iter 16: train loss 1.91070. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 150.95it/s]\n",
      "epoch 10 iter 16: train loss 1.88337. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 124.53it/s]\n",
      "epoch 11 iter 16: train loss 1.87265. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 132.74it/s]\n",
      "epoch 12 iter 16: train loss 1.84704. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.18it/s]\n",
      "epoch 13 iter 16: train loss 1.84845. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.92it/s]\n",
      "epoch 14 iter 16: train loss 1.84220. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 135.81it/s]\n",
      "epoch 15 iter 16: train loss 1.83394. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 130.17it/s]\n",
      "epoch 16 iter 16: train loss 1.82918. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 133.44it/s]\n",
      "epoch 17 iter 16: train loss 1.82607. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 142.96it/s]\n",
      "epoch 18 iter 16: train loss 1.82034. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.40it/s]\n",
      "epoch 19 iter 16: train loss 1.81261. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 135.70it/s]\n",
      "epoch 20 iter 16: train loss 1.81175. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 152.48it/s]\n",
      "epoch 21 iter 16: train loss 1.81530. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 130.89it/s]\n",
      "epoch 22 iter 16: train loss 1.82107. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 134.17it/s]\n",
      "epoch 23 iter 16: train loss 1.82528. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 139.35it/s]\n",
      "epoch 24 iter 16: train loss 1.82045. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 136.77it/s]\n",
      "epoch 25 iter 16: train loss 1.81311. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 147.77it/s]\n",
      "epoch 26 iter 16: train loss 1.81072. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 138.92it/s]\n",
      "epoch 27 iter 16: train loss 1.81086. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.56it/s]\n",
      "epoch 28 iter 16: train loss 1.81255. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 131.51it/s]\n",
      "epoch 29 iter 16: train loss 1.81312. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 115.06it/s]\n",
      "epoch 30 iter 16: train loss 1.81216. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 114.86it/s]\n",
      "epoch 31 iter 16: train loss 1.81005. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.38it/s]\n",
      "epoch 32 iter 16: train loss 1.80756. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 124.80it/s]\n",
      "epoch 33 iter 16: train loss 1.80555. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.23it/s]\n",
      "epoch 34 iter 16: train loss 1.80425. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 130.35it/s]\n",
      "epoch 35 iter 16: train loss 1.80342. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 139.62it/s]\n",
      "epoch 36 iter 16: train loss 1.80289. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 144.32it/s]\n",
      "epoch 37 iter 16: train loss 1.80268. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 133.54it/s]\n",
      "epoch 38 iter 16: train loss 1.80314. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.94it/s]\n",
      "epoch 39 iter 16: train loss 1.80388. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.51it/s]\n",
      "epoch 40 iter 16: train loss 1.80428. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 121.97it/s]\n",
      "epoch 41 iter 16: train loss 1.80364. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 130.96it/s]\n",
      "epoch 42 iter 16: train loss 1.80264. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 115.76it/s]\n",
      "epoch 43 iter 16: train loss 1.80211. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 143.92it/s]\n",
      "epoch 44 iter 16: train loss 1.80195. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.81it/s]\n",
      "epoch 45 iter 16: train loss 1.80190. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.91it/s]\n",
      "epoch 46 iter 16: train loss 1.80194. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 144.68it/s]\n",
      "epoch 47 iter 16: train loss 1.80208. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 132.56it/s]\n",
      "epoch 48 iter 16: train loss 1.80219. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.84it/s]\n",
      "epoch 49 iter 16: train loss 1.80203. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 134.37it/s]\n",
      "epoch 50 iter 16: train loss 1.80164. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 136.44it/s]\n",
      "epoch 51 iter 16: train loss 1.80147. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 142.90it/s]\n",
      "epoch 52 iter 16: train loss 1.80153. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.76it/s]\n",
      "epoch 53 iter 16: train loss 1.80158. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 151.08it/s]\n",
      "epoch 54 iter 16: train loss 1.80158. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 152.61it/s]\n",
      "epoch 55 iter 16: train loss 1.80152. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 139.25it/s]\n",
      "epoch 56 iter 16: train loss 1.80144. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 128.67it/s]\n",
      "epoch 57 iter 16: train loss 1.80132. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 140.96it/s]\n",
      "epoch 58 iter 16: train loss 1.80119. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 170.67it/s]\n",
      "epoch 59 iter 16: train loss 1.80120. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 139.17it/s]\n",
      "epoch 60 iter 16: train loss 1.80129. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 151.21it/s]\n",
      "epoch 61 iter 16: train loss 1.80134. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.09it/s]\n",
      "epoch 62 iter 16: train loss 1.80135. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 127.22it/s]\n",
      "epoch 63 iter 16: train loss 1.80128. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 147.94it/s]\n",
      "epoch 64 iter 16: train loss 1.80118. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 126.39it/s]\n",
      "epoch 65 iter 16: train loss 1.80112. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 136.69it/s]\n",
      "epoch 66 iter 16: train loss 1.80115. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 125.71it/s]\n",
      "epoch 67 iter 16: train loss 1.80124. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 122.14it/s]\n",
      "epoch 68 iter 16: train loss 1.80159. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 127.20it/s]\n",
      "epoch 69 iter 16: train loss 1.80228. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 122.78it/s]\n",
      "epoch 70 iter 16: train loss 1.80289. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.50it/s]\n",
      "epoch 71 iter 16: train loss 1.80241. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 136.61it/s]\n",
      "epoch 72 iter 16: train loss 1.80211. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 145.44it/s]\n",
      "epoch 73 iter 16: train loss 1.80177. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 128.60it/s]\n",
      "epoch 74 iter 16: train loss 1.80169. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 151.98it/s]\n",
      "epoch 75 iter 16: train loss 1.80167. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 90.28it/s]\n",
      "epoch 76 iter 16: train loss 1.80155. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 126.31it/s]\n",
      "epoch 77 iter 16: train loss 1.80148. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 169.18it/s]\n",
      "epoch 78 iter 16: train loss 1.80141. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 115.78it/s]\n",
      "epoch 79 iter 16: train loss 1.80124. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 124.11it/s]\n",
      "epoch 80 iter 16: train loss 1.80114. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.72it/s]\n",
      "epoch 81 iter 16: train loss 1.80105. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 130.70it/s]\n",
      "epoch 82 iter 16: train loss 1.80093. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 133.87it/s]\n",
      "epoch 83 iter 16: train loss 1.80080. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 126.24it/s]\n",
      "epoch 84 iter 16: train loss 1.80056. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 133.52it/s]\n",
      "epoch 85 iter 16: train loss 1.80035. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 138.12it/s]\n",
      "epoch 86 iter 16: train loss 1.80007. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 144.37it/s]\n",
      "epoch 87 iter 16: train loss 1.79981. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.02it/s]\n",
      "epoch 88 iter 16: train loss 1.79950. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.06it/s]\n",
      "epoch 89 iter 16: train loss 1.79920. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 141.98it/s]\n",
      "epoch 90 iter 16: train loss 1.79889. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 149.62it/s]\n",
      "epoch 91 iter 16: train loss 1.79854. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 135.80it/s]\n",
      "epoch 92 iter 16: train loss 1.79821. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.94it/s]\n",
      "epoch 93 iter 16: train loss 1.79788. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 128.14it/s]\n",
      "epoch 94 iter 16: train loss 1.79753. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 144.15it/s]\n",
      "epoch 95 iter 16: train loss 1.79722. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 134.30it/s]\n",
      "epoch 96 iter 16: train loss 1.79693. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 134.75it/s]\n",
      "epoch 97 iter 16: train loss 1.79666. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 127.50it/s]\n",
      "epoch 98 iter 16: train loss 1.79635. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 139.81it/s]\n",
      "epoch 99 iter 16: train loss 1.79608. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 129.71it/s]\n",
      "epoch 100 iter 16: train loss 1.79587. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 127.27it/s]\n",
      "epoch 101 iter 16: train loss 1.79572. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 132.20it/s]\n",
      "epoch 102 iter 16: train loss 1.79559. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 134.12it/s]\n",
      "epoch 103 iter 16: train loss 1.79551. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 130.24it/s]\n",
      "epoch 104 iter 16: train loss 1.79547. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 145.66it/s]\n",
      "epoch 105 iter 16: train loss 1.79546. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 149.35it/s]\n",
      "epoch 106 iter 16: train loss 1.79536. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 133.45it/s]\n",
      "epoch 107 iter 16: train loss 1.79522. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 133.44it/s]\n",
      "epoch 108 iter 16: train loss 1.79518. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 114.35it/s]\n",
      "epoch 109 iter 16: train loss 1.79522. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 112.76it/s]\n",
      "epoch 110 iter 16: train loss 1.79527. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 136.48it/s]\n",
      "epoch 111 iter 16: train loss 1.79534. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 142.20it/s]\n",
      "epoch 112 iter 16: train loss 1.79541. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 152.63it/s]\n",
      "epoch 113 iter 16: train loss 1.79541. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 137.62it/s]\n",
      "epoch 114 iter 16: train loss 1.79533. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 131.75it/s]\n",
      "epoch 115 iter 16: train loss 1.79527. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 137.72it/s]\n",
      "epoch 116 iter 16: train loss 1.79527. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 158.83it/s]\n",
      "epoch 117 iter 16: train loss 1.79528. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 143.53it/s]\n",
      "epoch 118 iter 16: train loss 1.79526. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.15it/s]\n",
      "epoch 119 iter 16: train loss 1.79520. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 134.24it/s]\n",
      "epoch 120 iter 16: train loss 1.79513. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 154.12it/s]\n",
      "epoch 121 iter 16: train loss 1.79505. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 145.90it/s]\n",
      "epoch 122 iter 16: train loss 1.79495. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 136.00it/s]\n",
      "epoch 123 iter 16: train loss 1.79483. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 138.55it/s]\n",
      "epoch 124 iter 16: train loss 1.79467. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 130.72it/s]\n",
      "epoch 125 iter 16: train loss 1.79450. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 133.12it/s]\n",
      "epoch 126 iter 16: train loss 1.79431. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 161.53it/s]\n",
      "epoch 127 iter 16: train loss 1.79402. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 168.31it/s]\n",
      "epoch 128 iter 16: train loss 1.79377. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 150.22it/s]\n",
      "epoch 129 iter 16: train loss 1.79356. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 134.16it/s]\n",
      "epoch 130 iter 16: train loss 1.79337. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.48it/s]\n",
      "epoch 131 iter 16: train loss 1.79319. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 151.88it/s]\n",
      "epoch 132 iter 16: train loss 1.79296. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 149.05it/s]\n",
      "epoch 133 iter 16: train loss 1.79266. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 148.40it/s]\n",
      "epoch 134 iter 16: train loss 1.79233. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.90it/s]\n",
      "epoch 135 iter 16: train loss 1.79201. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.09it/s]\n",
      "epoch 136 iter 16: train loss 1.79177. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 147.80it/s]\n",
      "epoch 137 iter 16: train loss 1.79171. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 141.47it/s]\n",
      "epoch 138 iter 16: train loss 1.79197. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 104.25it/s]\n",
      "epoch 139 iter 16: train loss 1.79248. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 145.24it/s]\n",
      "epoch 140 iter 16: train loss 1.79308. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 148.98it/s]\n",
      "epoch 141 iter 16: train loss 1.79351. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 132.33it/s]\n",
      "epoch 142 iter 16: train loss 1.79371. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 145.63it/s]\n",
      "epoch 143 iter 16: train loss 1.79387. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 150.27it/s]\n",
      "epoch 144 iter 16: train loss 1.79395. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.69it/s]\n",
      "epoch 145 iter 16: train loss 1.79376. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 164.97it/s]\n",
      "epoch 146 iter 16: train loss 1.79328. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 132.74it/s]\n",
      "epoch 147 iter 16: train loss 1.79269. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 163.17it/s]\n",
      "epoch 148 iter 16: train loss 1.79206. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 142.30it/s]\n",
      "epoch 149 iter 16: train loss 1.79151. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 149.94it/s]\n",
      "epoch 150 iter 16: train loss 1.79069. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 138.30it/s]\n",
      "epoch 151 iter 16: train loss 1.79087. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 139.55it/s]\n",
      "epoch 152 iter 16: train loss 1.79843. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 133.86it/s]\n",
      "epoch 153 iter 16: train loss 1.79355. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 124.52it/s]\n",
      "epoch 154 iter 16: train loss 1.79332. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 141.20it/s]\n",
      "epoch 155 iter 16: train loss 1.79420. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 124.30it/s]\n",
      "epoch 156 iter 16: train loss 1.79423. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.91it/s]\n",
      "epoch 157 iter 16: train loss 1.79430. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 151.67it/s]\n",
      "epoch 158 iter 16: train loss 1.79446. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 126.98it/s]\n",
      "epoch 159 iter 16: train loss 1.79454. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.57it/s]\n",
      "epoch 160 iter 16: train loss 1.79458. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 133.24it/s]\n",
      "epoch 161 iter 16: train loss 1.79457. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.97it/s]\n",
      "epoch 162 iter 16: train loss 1.79448. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 112.52it/s]\n",
      "epoch 163 iter 16: train loss 1.79428. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 89.62it/s]\n",
      "epoch 164 iter 16: train loss 1.79398. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 125.63it/s]\n",
      "epoch 165 iter 16: train loss 1.79360. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.88it/s]\n",
      "epoch 166 iter 16: train loss 1.79340. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 99.05it/s] \n",
      "epoch 167 iter 16: train loss 1.79334. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 121.26it/s]\n",
      "epoch 168 iter 16: train loss 1.79338. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.23it/s]\n",
      "epoch 169 iter 16: train loss 1.79351. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 86.75it/s]\n",
      "epoch 170 iter 16: train loss 1.79393. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 129.43it/s]\n",
      "epoch 171 iter 16: train loss 1.79491. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 131.48it/s]\n",
      "epoch 172 iter 16: train loss 1.81179. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 115.95it/s]\n",
      "epoch 173 iter 16: train loss 1.80378. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 131.66it/s]\n",
      "epoch 174 iter 16: train loss 1.79997. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 132.87it/s]\n",
      "epoch 175 iter 16: train loss 1.79664. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 81.15it/s]\n",
      "epoch 176 iter 16: train loss 1.79408. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.84it/s]\n",
      "epoch 177 iter 16: train loss 1.78981. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.77it/s]\n",
      "epoch 178 iter 16: train loss 1.79422. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.15it/s]\n",
      "epoch 179 iter 16: train loss 1.79564. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.51it/s]\n",
      "epoch 180 iter 16: train loss 1.79552. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.55it/s]\n",
      "epoch 181 iter 16: train loss 1.79825. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 90.35it/s]\n",
      "epoch 182 iter 16: train loss 1.79359. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.64it/s]\n",
      "epoch 183 iter 16: train loss 1.79421. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.65it/s]\n",
      "epoch 184 iter 16: train loss 1.79519. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.06it/s]\n",
      "epoch 185 iter 16: train loss 1.79488. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 115.72it/s]\n",
      "epoch 186 iter 16: train loss 1.79586. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 77.60it/s] \n",
      "epoch 187 iter 16: train loss 1.79531. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 135.91it/s]\n",
      "epoch 188 iter 16: train loss 1.79599. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.90it/s]\n",
      "epoch 189 iter 16: train loss 1.79636. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.01it/s]\n",
      "epoch 190 iter 16: train loss 1.79460. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.82it/s]\n",
      "epoch 191 iter 16: train loss 1.79398. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.74it/s]\n",
      "epoch 192 iter 16: train loss 1.79394. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.99it/s]\n",
      "epoch 193 iter 16: train loss 1.79108. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 141.05it/s]\n",
      "epoch 194 iter 16: train loss 1.79415. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 89.05it/s]\n",
      "epoch 195 iter 16: train loss 1.79298. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 122.51it/s]\n",
      "epoch 196 iter 16: train loss 1.79790. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 87.04it/s]\n",
      "epoch 197 iter 16: train loss 1.79396. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 141.90it/s]\n",
      "epoch 198 iter 16: train loss 1.79569. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.77it/s]\n",
      "epoch 199 iter 16: train loss 1.79631. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.92it/s]\n",
      "epoch 200 iter 16: train loss 1.79580. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 93.87it/s] \n",
      "epoch 201 iter 16: train loss 1.79687. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.75it/s]\n",
      "epoch 202 iter 16: train loss 1.79597. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.77it/s]\n",
      "epoch 203 iter 16: train loss 1.79637. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 125.86it/s]\n",
      "epoch 204 iter 16: train loss 1.79761. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 128.14it/s]\n",
      "epoch 205 iter 16: train loss 1.79541. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 99.91it/s] \n",
      "epoch 206 iter 16: train loss 1.79449. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.17it/s]\n",
      "epoch 207 iter 16: train loss 1.79451. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 127.97it/s]\n",
      "epoch 208 iter 16: train loss 1.79000. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 128.32it/s]\n",
      "epoch 209 iter 16: train loss 1.78874. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.38it/s]\n",
      "epoch 210 iter 16: train loss 1.79300. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 79.08it/s]\n",
      "epoch 211 iter 16: train loss 1.79272. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.42it/s]\n",
      "epoch 212 iter 16: train loss 1.79439. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.13it/s]\n",
      "epoch 213 iter 16: train loss 1.80165. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.91it/s]\n",
      "epoch 214 iter 16: train loss 1.80165. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 96.08it/s]\n",
      "epoch 215 iter 16: train loss 1.80168. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 80.21it/s]\n",
      "epoch 216 iter 16: train loss 1.79684. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.09it/s]\n",
      "epoch 217 iter 16: train loss 1.79365. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 122.18it/s]\n",
      "epoch 218 iter 16: train loss 1.78921. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.21it/s]\n",
      "epoch 219 iter 16: train loss 1.79236. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 63.88it/s]\n",
      "epoch 220 iter 16: train loss 1.79258. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 94.87it/s]\n",
      "epoch 221 iter 16: train loss 1.79428. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 124.91it/s]\n",
      "epoch 222 iter 16: train loss 1.79581. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.53it/s]\n",
      "epoch 223 iter 16: train loss 1.79645. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 79.83it/s]\n",
      "epoch 224 iter 16: train loss 1.79744. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.88it/s]\n",
      "epoch 225 iter 16: train loss 1.79831. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 149.99it/s]\n",
      "epoch 226 iter 16: train loss 1.79954. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 126.14it/s]\n",
      "epoch 227 iter 16: train loss 1.79649. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 94.09it/s]\n",
      "epoch 228 iter 16: train loss 1.78953. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.82it/s]\n",
      "epoch 229 iter 16: train loss 1.79122. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.52it/s]\n",
      "epoch 230 iter 16: train loss 1.79282. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 137.37it/s]\n",
      "epoch 231 iter 16: train loss 1.79474. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.68it/s]\n",
      "epoch 232 iter 16: train loss 1.79642. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 87.32it/s]\n",
      "epoch 233 iter 16: train loss 1.79755. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 112.25it/s]\n",
      "epoch 234 iter 16: train loss 1.79145. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 104.60it/s]\n",
      "epoch 235 iter 16: train loss 1.79246. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.94it/s]\n",
      "epoch 236 iter 16: train loss 1.79312. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 122.00it/s]\n",
      "epoch 237 iter 16: train loss 1.79389. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 129.25it/s]\n",
      "epoch 238 iter 16: train loss 1.79530. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.66it/s]\n",
      "epoch 239 iter 16: train loss 1.79630. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.02it/s]\n",
      "epoch 240 iter 16: train loss 1.79751. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.35it/s]\n",
      "epoch 241 iter 16: train loss 1.80053. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.96it/s]\n",
      "epoch 242 iter 16: train loss 1.80344. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.94it/s]\n",
      "epoch 243 iter 16: train loss 1.80566. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 98.90it/s]\n",
      "epoch 244 iter 16: train loss 1.79423. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.19it/s]\n",
      "epoch 245 iter 16: train loss 1.79944. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.21it/s]\n",
      "epoch 246 iter 16: train loss 1.79832. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 129.87it/s]\n",
      "epoch 247 iter 16: train loss 1.79050. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 92.72it/s]\n",
      "epoch 248 iter 16: train loss 1.79529. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 114.64it/s]\n",
      "epoch 249 iter 16: train loss 1.79546. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 132.32it/s]\n",
      "epoch 250 iter 16: train loss 1.79715. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 124.13it/s]\n",
      "epoch 251 iter 16: train loss 1.79887. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.42it/s]\n",
      "epoch 252 iter 16: train loss 1.80043. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 92.74it/s]\n",
      "epoch 253 iter 16: train loss 1.80197. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.35it/s]\n",
      "epoch 254 iter 16: train loss 1.79787. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 147.15it/s]\n",
      "epoch 255 iter 16: train loss 1.78792. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.54it/s]\n",
      "epoch 256 iter 16: train loss 1.79218. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.19it/s]\n",
      "epoch 257 iter 16: train loss 1.79464. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.14it/s]\n",
      "epoch 258 iter 16: train loss 1.79684. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 99.72it/s] \n",
      "epoch 259 iter 16: train loss 1.79841. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 91.26it/s] \n",
      "epoch 260 iter 16: train loss 1.80034. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 133.21it/s]\n",
      "epoch 261 iter 16: train loss 1.79732. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.92it/s]\n",
      "epoch 262 iter 16: train loss 1.79709. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 124.60it/s]\n",
      "epoch 263 iter 16: train loss 1.79819. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 87.65it/s]\n",
      "epoch 264 iter 16: train loss 1.78835. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.54it/s]\n",
      "epoch 265 iter 16: train loss 1.80926. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 114.64it/s]\n",
      "epoch 266 iter 16: train loss 1.79852. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 83.80it/s] \n",
      "epoch 267 iter 16: train loss 1.79827. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.24it/s]\n",
      "epoch 268 iter 16: train loss 1.79988. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.86it/s]\n",
      "epoch 269 iter 16: train loss 1.79186. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.37it/s]\n",
      "epoch 270 iter 16: train loss 1.80141. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.32it/s]\n",
      "epoch 271 iter 16: train loss 1.79629. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.25it/s]\n",
      "epoch 272 iter 16: train loss 1.79895. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 127.63it/s]\n",
      "epoch 273 iter 16: train loss 1.80046. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 75.77it/s] \n",
      "epoch 274 iter 16: train loss 1.80088. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 96.43it/s]\n",
      "epoch 275 iter 16: train loss 1.80138. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 126.77it/s]\n",
      "epoch 276 iter 16: train loss 1.78948. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 129.31it/s]\n",
      "epoch 277 iter 16: train loss 1.81649. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 78.85it/s]\n",
      "epoch 278 iter 16: train loss 1.80204. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.14it/s]\n",
      "epoch 279 iter 16: train loss 1.79935. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.33it/s]\n",
      "epoch 280 iter 16: train loss 1.80100. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 126.14it/s]\n",
      "epoch 281 iter 16: train loss 1.79168. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.68it/s]\n",
      "epoch 282 iter 16: train loss 1.81646. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 138.62it/s]\n",
      "epoch 283 iter 16: train loss 1.80016. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 130.26it/s]\n",
      "epoch 284 iter 16: train loss 1.79955. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 91.14it/s]\n",
      "epoch 285 iter 16: train loss 1.80131. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.61it/s]\n",
      "epoch 286 iter 16: train loss 1.78613. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 115.79it/s]\n",
      "epoch 287 iter 16: train loss 1.83072. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.87it/s]\n",
      "epoch 288 iter 16: train loss 1.81039. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 100.82it/s]\n",
      "epoch 289 iter 16: train loss 1.79747. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.32it/s]\n",
      "epoch 290 iter 16: train loss 1.79802. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.92it/s]\n",
      "epoch 291 iter 16: train loss 1.79939. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.03it/s]\n",
      "epoch 292 iter 16: train loss 1.80957. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.61it/s]\n",
      "epoch 293 iter 16: train loss 1.79787. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 95.89it/s]\n",
      "epoch 294 iter 16: train loss 1.79678. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 89.63it/s] \n",
      "epoch 295 iter 16: train loss 1.79771. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 112.70it/s]\n",
      "epoch 296 iter 16: train loss 1.79893. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 100.10it/s]\n",
      "epoch 297 iter 16: train loss 1.80006. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 95.25it/s]\n",
      "epoch 298 iter 16: train loss 1.80123. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 114.78it/s]\n",
      "epoch 299 iter 16: train loss 1.80625. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.49it/s]\n",
      "epoch 300 iter 16: train loss 1.81037. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 114.36it/s]\n",
      "epoch 301 iter 16: train loss 1.79405. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.58it/s]\n",
      "epoch 302 iter 16: train loss 1.80299. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 131.66it/s]\n",
      "epoch 303 iter 16: train loss 1.80451. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.80it/s]\n",
      "epoch 304 iter 16: train loss 1.80016. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 129.52it/s]\n",
      "epoch 305 iter 16: train loss 1.79955. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 84.66it/s] \n",
      "epoch 306 iter 16: train loss 1.80053. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 126.67it/s]\n",
      "epoch 307 iter 16: train loss 1.78755. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 136.93it/s]\n",
      "epoch 308 iter 16: train loss 1.82626. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 74.78it/s]\n",
      "epoch 309 iter 16: train loss 1.80098. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 89.62it/s]\n",
      "epoch 310 iter 16: train loss 1.79909. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 129.93it/s]\n",
      "epoch 311 iter 16: train loss 1.78537. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 121.08it/s]\n",
      "epoch 312 iter 16: train loss 1.82214. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.42it/s]\n",
      "epoch 313 iter 16: train loss 1.80211. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 107.00it/s]\n",
      "epoch 314 iter 16: train loss 1.80008. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.51it/s]\n",
      "epoch 315 iter 16: train loss 1.79885. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.20it/s]\n",
      "epoch 316 iter 16: train loss 1.79353. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 146.00it/s]\n",
      "epoch 317 iter 16: train loss 1.81254. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.84it/s]\n",
      "epoch 318 iter 16: train loss 1.79873. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 100.33it/s]\n",
      "epoch 319 iter 16: train loss 1.79993. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.60it/s]\n",
      "epoch 320 iter 16: train loss 1.80117. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.79it/s]\n",
      "epoch 321 iter 16: train loss 1.80098. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 82.54it/s]\n",
      "epoch 322 iter 16: train loss 1.80112. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 139.13it/s]\n",
      "epoch 323 iter 16: train loss 1.80106. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.33it/s]\n",
      "epoch 324 iter 16: train loss 1.80054. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.53it/s]\n",
      "epoch 325 iter 16: train loss 1.79973. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 107.34it/s]\n",
      "epoch 326 iter 16: train loss 1.80191. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.84it/s]\n",
      "epoch 327 iter 16: train loss 1.80295. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 104.41it/s]\n",
      "epoch 328 iter 16: train loss 1.80597. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.32it/s]\n",
      "epoch 329 iter 16: train loss 1.80923. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.46it/s]\n",
      "epoch 330 iter 16: train loss 1.79379. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 144.03it/s]\n",
      "epoch 331 iter 16: train loss 1.80228. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 136.15it/s]\n",
      "epoch 332 iter 16: train loss 1.79998. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.49it/s]\n",
      "epoch 333 iter 16: train loss 1.80040. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.74it/s]\n",
      "epoch 334 iter 16: train loss 1.80195. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 130.39it/s]\n",
      "epoch 335 iter 16: train loss 1.80321. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.47it/s]\n",
      "epoch 336 iter 16: train loss 1.80342. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 141.28it/s]\n",
      "epoch 337 iter 16: train loss 1.78621. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 122.25it/s]\n",
      "epoch 338 iter 16: train loss 1.83409. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 104.39it/s]\n",
      "epoch 339 iter 16: train loss 1.80050. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 133.93it/s]\n",
      "epoch 340 iter 16: train loss 1.80071. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.44it/s]\n",
      "epoch 341 iter 16: train loss 1.80563. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 96.14it/s]\n",
      "epoch 342 iter 16: train loss 1.80375. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 130.33it/s]\n",
      "epoch 343 iter 16: train loss 1.79827. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 115.58it/s]\n",
      "epoch 344 iter 16: train loss 1.81088. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 122.79it/s]\n",
      "epoch 345 iter 16: train loss 1.81213. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 100.43it/s]\n",
      "epoch 346 iter 16: train loss 1.81066. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 104.85it/s]\n",
      "epoch 347 iter 16: train loss 1.80903. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 86.97it/s]\n",
      "epoch 348 iter 16: train loss 1.78888. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.11it/s]\n",
      "epoch 349 iter 16: train loss 1.79778. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.15it/s]\n",
      "epoch 350 iter 16: train loss 1.80276. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.43it/s]\n",
      "epoch 351 iter 16: train loss 1.80858. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 124.44it/s]\n",
      "epoch 352 iter 16: train loss 1.80813. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 139.06it/s]\n",
      "epoch 353 iter 16: train loss 1.79124. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.87it/s]\n",
      "epoch 354 iter 16: train loss 1.80163. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 139.13it/s]\n",
      "epoch 355 iter 16: train loss 1.79596. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 131.13it/s]\n",
      "epoch 356 iter 16: train loss 1.79986. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.91it/s]\n",
      "epoch 357 iter 16: train loss 1.80702. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.06it/s]\n",
      "epoch 358 iter 16: train loss 1.80933. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.56it/s]\n",
      "epoch 359 iter 16: train loss 1.79485. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 104.69it/s]\n",
      "epoch 360 iter 16: train loss 1.79420. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.22it/s]\n",
      "epoch 361 iter 16: train loss 1.80211. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.12it/s]\n",
      "epoch 362 iter 16: train loss 1.78459. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.96it/s]\n",
      "epoch 363 iter 16: train loss 1.83050. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.20it/s]\n",
      "epoch 364 iter 16: train loss 1.80166. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.28it/s]\n",
      "epoch 365 iter 16: train loss 1.80028. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 85.14it/s] \n",
      "epoch 366 iter 16: train loss 1.79946. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.53it/s]\n",
      "epoch 367 iter 16: train loss 1.79812. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.99it/s]\n",
      "epoch 368 iter 16: train loss 1.79968. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 83.71it/s]\n",
      "epoch 369 iter 16: train loss 1.78750. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 129.09it/s]\n",
      "epoch 370 iter 16: train loss 1.79930. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.72it/s]\n",
      "epoch 371 iter 16: train loss 1.80970. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 122.87it/s]\n",
      "epoch 372 iter 16: train loss 1.81112. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.44it/s]\n",
      "epoch 373 iter 16: train loss 1.79923. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 122.14it/s]\n",
      "epoch 374 iter 16: train loss 1.79731. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 80.23it/s]\n",
      "epoch 375 iter 16: train loss 1.80316. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.43it/s]\n",
      "epoch 376 iter 16: train loss 1.80664. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.91it/s]\n",
      "epoch 377 iter 16: train loss 1.80478. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 92.78it/s] \n",
      "epoch 378 iter 16: train loss 1.80128. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 97.15it/s]\n",
      "epoch 379 iter 16: train loss 1.80157. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 121.02it/s]\n",
      "epoch 380 iter 16: train loss 1.80325. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 95.03it/s]\n",
      "epoch 381 iter 16: train loss 1.78817. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.06it/s]\n",
      "epoch 382 iter 16: train loss 1.83179. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 133.67it/s]\n",
      "epoch 383 iter 16: train loss 1.80392. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 82.96it/s]\n",
      "epoch 384 iter 16: train loss 1.80115. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.53it/s]\n",
      "epoch 385 iter 16: train loss 1.79725. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 126.95it/s]\n",
      "epoch 386 iter 16: train loss 1.80182. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 91.26it/s]\n",
      "epoch 387 iter 16: train loss 1.81861. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 121.82it/s]\n",
      "epoch 388 iter 16: train loss 1.80039. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.39it/s]\n",
      "epoch 389 iter 16: train loss 1.80119. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 122.69it/s]\n",
      "epoch 390 iter 16: train loss 1.80313. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 126.22it/s]\n",
      "epoch 391 iter 16: train loss 1.80283. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.10it/s]\n",
      "epoch 392 iter 16: train loss 1.80288. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.95it/s]\n",
      "epoch 393 iter 16: train loss 1.80287. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.74it/s]\n",
      "epoch 394 iter 16: train loss 1.80274. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.09it/s]\n",
      "epoch 395 iter 16: train loss 1.80272. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 89.35it/s] \n",
      "epoch 396 iter 16: train loss 1.80223. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.35it/s]\n",
      "epoch 397 iter 16: train loss 1.80204. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.10it/s]\n",
      "epoch 398 iter 16: train loss 1.80156. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.43it/s]\n",
      "epoch 399 iter 16: train loss 1.80135. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.50it/s]\n",
      "epoch 400 iter 16: train loss 1.80050. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.11it/s]\n",
      "epoch 401 iter 16: train loss 1.80008. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 74.27it/s]\n",
      "epoch 402 iter 16: train loss 1.79886. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 132.52it/s]\n",
      "epoch 403 iter 16: train loss 1.80269. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.26it/s]\n",
      "epoch 404 iter 16: train loss 1.80361. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 100.30it/s]\n",
      "epoch 405 iter 16: train loss 1.80627. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 124.87it/s]\n",
      "epoch 406 iter 16: train loss 1.81142. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 74.03it/s] \n",
      "epoch 407 iter 16: train loss 1.79516. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 94.09it/s]\n",
      "epoch 408 iter 16: train loss 1.80601. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.92it/s]\n",
      "epoch 409 iter 16: train loss 1.80300. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.78it/s]\n",
      "epoch 410 iter 16: train loss 1.78421. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 129.32it/s]\n",
      "epoch 411 iter 16: train loss 1.83278. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 71.48it/s]\n",
      "epoch 412 iter 16: train loss 1.79903. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 112.19it/s]\n",
      "epoch 413 iter 16: train loss 1.81741. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 125.39it/s]\n",
      "epoch 414 iter 16: train loss 1.78550. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.36it/s]\n",
      "epoch 415 iter 16: train loss 1.81405. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 121.58it/s]\n",
      "epoch 416 iter 16: train loss 1.80824. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 73.01it/s] \n",
      "epoch 417 iter 16: train loss 1.79914. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.66it/s]\n",
      "epoch 418 iter 16: train loss 1.81856. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.20it/s]\n",
      "epoch 419 iter 16: train loss 1.80670. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 93.63it/s] \n",
      "epoch 420 iter 16: train loss 1.79851. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.10it/s]\n",
      "epoch 421 iter 16: train loss 1.79884. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 92.89it/s]\n",
      "epoch 422 iter 16: train loss 1.79919. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 107.28it/s]\n",
      "epoch 423 iter 16: train loss 1.80025. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 121.82it/s]\n",
      "epoch 424 iter 16: train loss 1.79931. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.79it/s]\n",
      "epoch 425 iter 16: train loss 1.80011. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 114.59it/s]\n",
      "epoch 426 iter 16: train loss 1.79915. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.17it/s]\n",
      "epoch 427 iter 16: train loss 1.80901. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.58it/s]\n",
      "epoch 428 iter 16: train loss 1.81532. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 124.56it/s]\n",
      "epoch 429 iter 16: train loss 1.80804. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 125.67it/s]\n",
      "epoch 430 iter 16: train loss 1.80137. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 107.40it/s]\n",
      "epoch 431 iter 16: train loss 1.80095. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.36it/s]\n",
      "epoch 432 iter 16: train loss 1.80167. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.56it/s]\n",
      "epoch 433 iter 16: train loss 1.80167. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 121.23it/s]\n",
      "epoch 434 iter 16: train loss 1.80167. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 122.18it/s]\n",
      "epoch 435 iter 16: train loss 1.80125. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.04it/s]\n",
      "epoch 436 iter 16: train loss 1.80123. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.50it/s]\n",
      "epoch 437 iter 16: train loss 1.80060. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 70.98it/s]\n",
      "epoch 438 iter 16: train loss 1.80092. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 112.26it/s]\n",
      "epoch 439 iter 16: train loss 1.79975. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.10it/s]\n",
      "epoch 440 iter 16: train loss 1.80102. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.96it/s]\n",
      "epoch 441 iter 16: train loss 1.79917. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 134.48it/s]\n",
      "epoch 442 iter 16: train loss 1.80109. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 99.27it/s] \n",
      "epoch 443 iter 16: train loss 1.79772. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.06it/s]\n",
      "epoch 444 iter 16: train loss 1.80617. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 77.35it/s]\n",
      "epoch 445 iter 16: train loss 1.81711. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 125.50it/s]\n",
      "epoch 446 iter 16: train loss 1.80845. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.58it/s]\n",
      "epoch 447 iter 16: train loss 1.78934. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.69it/s]\n",
      "epoch 448 iter 16: train loss 1.79737. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.22it/s]\n",
      "epoch 449 iter 16: train loss 1.80003. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 84.79it/s]\n",
      "epoch 450 iter 16: train loss 1.79969. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 107.88it/s]\n",
      "epoch 451 iter 16: train loss 1.79911. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 115.42it/s]\n",
      "epoch 452 iter 16: train loss 1.79779. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 89.64it/s]\n",
      "epoch 453 iter 16: train loss 1.80216. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.09it/s]\n",
      "epoch 454 iter 16: train loss 1.80593. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 79.74it/s]\n",
      "epoch 455 iter 16: train loss 1.81278. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.77it/s]\n",
      "epoch 456 iter 16: train loss 1.81012. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 100.54it/s]\n",
      "epoch 457 iter 16: train loss 1.79124. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.10it/s]\n",
      "epoch 458 iter 16: train loss 1.80805. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.70it/s]\n",
      "epoch 459 iter 16: train loss 1.80933. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 126.84it/s]\n",
      "epoch 460 iter 16: train loss 1.80959. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 100.48it/s]\n",
      "epoch 461 iter 16: train loss 1.80672. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 131.17it/s]\n",
      "epoch 462 iter 16: train loss 1.80254. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.30it/s]\n",
      "epoch 463 iter 16: train loss 1.80248. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 107.93it/s]\n",
      "epoch 464 iter 16: train loss 1.80247. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.84it/s]\n",
      "epoch 465 iter 16: train loss 1.80226. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 92.50it/s]\n",
      "epoch 466 iter 16: train loss 1.80183. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 114.14it/s]\n",
      "epoch 467 iter 16: train loss 1.80143. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 79.86it/s]\n",
      "epoch 468 iter 16: train loss 1.80114. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.57it/s]\n",
      "epoch 469 iter 16: train loss 1.80048. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 122.52it/s]\n",
      "epoch 470 iter 16: train loss 1.80078. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 125.77it/s]\n",
      "epoch 471 iter 16: train loss 1.80072. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 125.39it/s]\n",
      "epoch 472 iter 16: train loss 1.80048. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 81.40it/s]\n",
      "epoch 473 iter 16: train loss 1.80110. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.01it/s]\n",
      "epoch 474 iter 16: train loss 1.79959. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 84.55it/s] \n",
      "epoch 475 iter 16: train loss 1.80136. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.43it/s]\n",
      "epoch 476 iter 16: train loss 1.79957. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.82it/s]\n",
      "epoch 477 iter 16: train loss 1.80075. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 66.01it/s]\n",
      "epoch 478 iter 16: train loss 1.79941. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 97.93it/s]\n",
      "epoch 479 iter 16: train loss 1.80058. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 112.46it/s]\n",
      "epoch 480 iter 16: train loss 1.79875. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 136.10it/s]\n",
      "epoch 481 iter 16: train loss 1.80041. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.09it/s]\n",
      "epoch 482 iter 16: train loss 1.79885. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.80it/s]\n",
      "epoch 483 iter 16: train loss 1.80001. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 79.43it/s]\n",
      "epoch 484 iter 16: train loss 1.79891. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 122.80it/s]\n",
      "epoch 485 iter 16: train loss 1.80465. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 114.23it/s]\n",
      "epoch 486 iter 16: train loss 1.81824. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.91it/s]\n",
      "epoch 487 iter 16: train loss 1.80984. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.89it/s]\n",
      "epoch 488 iter 16: train loss 1.80526. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.99it/s]\n",
      "epoch 489 iter 16: train loss 1.78859. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.31it/s]\n",
      "epoch 490 iter 16: train loss 1.81582. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 72.72it/s] \n",
      "epoch 491 iter 16: train loss 1.80602. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 112.74it/s]\n",
      "epoch 492 iter 16: train loss 1.78047. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.56it/s]\n",
      "epoch 493 iter 16: train loss 1.82849. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 95.74it/s]\n",
      "epoch 494 iter 16: train loss 1.80518. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.15it/s]\n",
      "epoch 495 iter 16: train loss 1.79869. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.73it/s]\n",
      "epoch 496 iter 16: train loss 1.81568. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 125.10it/s]\n",
      "epoch 497 iter 16: train loss 1.79973. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 114.87it/s]\n",
      "epoch 498 iter 16: train loss 1.79778. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.76it/s]\n",
      "epoch 499 iter 16: train loss 1.77945. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.67it/s]\n",
      "epoch 500 iter 16: train loss 1.79811. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.44it/s]\n",
      "epoch 501 iter 16: train loss 1.79912. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 125.59it/s]\n",
      "epoch 502 iter 16: train loss 1.81816. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.74it/s]\n",
      "epoch 503 iter 16: train loss 1.81515. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 98.81it/s]\n",
      "epoch 504 iter 16: train loss 1.80544. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 127.22it/s]\n",
      "epoch 505 iter 16: train loss 1.79210. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.68it/s]\n",
      "epoch 506 iter 16: train loss 1.80666. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.82it/s]\n",
      "epoch 507 iter 16: train loss 1.80356. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.15it/s]\n",
      "epoch 508 iter 16: train loss 1.80183. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.30it/s]\n",
      "epoch 509 iter 16: train loss 1.80139. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 124.16it/s]\n",
      "epoch 510 iter 16: train loss 1.80106. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.12it/s]\n",
      "epoch 511 iter 16: train loss 1.80053. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 114.13it/s]\n",
      "epoch 512 iter 16: train loss 1.80045. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 121.27it/s]\n",
      "epoch 513 iter 16: train loss 1.79962. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 99.10it/s] \n",
      "epoch 514 iter 16: train loss 1.80031. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.45it/s]\n",
      "epoch 515 iter 16: train loss 1.79987. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.89it/s]\n",
      "epoch 516 iter 16: train loss 1.80000. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.82it/s]\n",
      "epoch 517 iter 16: train loss 1.79866. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.89it/s]\n",
      "epoch 518 iter 16: train loss 1.81238. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 83.04it/s]\n",
      "epoch 519 iter 16: train loss 1.81587. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.16it/s]\n",
      "epoch 520 iter 16: train loss 1.78477. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 115.04it/s]\n",
      "epoch 521 iter 16: train loss 1.79656. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 79.69it/s]\n",
      "epoch 522 iter 16: train loss 1.80857. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.05it/s]\n",
      "epoch 523 iter 16: train loss 1.81416. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 124.27it/s]\n",
      "epoch 524 iter 16: train loss 1.78839. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.02it/s]\n",
      "epoch 525 iter 16: train loss 1.79163. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 115.15it/s]\n",
      "epoch 526 iter 16: train loss 1.80841. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.29it/s]\n",
      "epoch 527 iter 16: train loss 1.81221. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.20it/s]\n",
      "epoch 528 iter 16: train loss 1.79623. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.32it/s]\n",
      "epoch 529 iter 16: train loss 1.80825. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 95.33it/s]\n",
      "epoch 530 iter 16: train loss 1.79623. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 81.24it/s]\n",
      "epoch 531 iter 16: train loss 1.80678. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.33it/s]\n",
      "epoch 532 iter 16: train loss 1.78466. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 97.01it/s]\n",
      "epoch 533 iter 16: train loss 1.79985. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 83.13it/s]\n",
      "epoch 534 iter 16: train loss 1.81556. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 126.25it/s]\n",
      "epoch 535 iter 16: train loss 1.80885. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.40it/s]\n",
      "epoch 536 iter 16: train loss 1.80494. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.02it/s]\n",
      "epoch 537 iter 16: train loss 1.80873. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 99.88it/s] \n",
      "epoch 538 iter 16: train loss 1.81065. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.30it/s]\n",
      "epoch 539 iter 16: train loss 1.80550. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 131.60it/s]\n",
      "epoch 540 iter 16: train loss 1.80160. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 139.27it/s]\n",
      "epoch 541 iter 16: train loss 1.80113. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.77it/s]\n",
      "epoch 542 iter 16: train loss 1.80094. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.94it/s]\n",
      "epoch 543 iter 16: train loss 1.80073. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.46it/s]\n",
      "epoch 544 iter 16: train loss 1.80105. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.65it/s]\n",
      "epoch 545 iter 16: train loss 1.80106. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.82it/s]\n",
      "epoch 546 iter 16: train loss 1.80105. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.75it/s]\n",
      "epoch 547 iter 16: train loss 1.80122. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 150.96it/s]\n",
      "epoch 548 iter 16: train loss 1.80106. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 157.62it/s]\n",
      "epoch 549 iter 16: train loss 1.80159. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 112.37it/s]\n",
      "epoch 550 iter 16: train loss 1.80121. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.90it/s]\n",
      "epoch 551 iter 16: train loss 1.80142. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.12it/s]\n",
      "epoch 552 iter 16: train loss 1.80144. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 79.68it/s]\n",
      "epoch 553 iter 16: train loss 1.80150. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 162.10it/s]\n",
      "epoch 554 iter 16: train loss 1.80144. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 161.33it/s]\n",
      "epoch 555 iter 16: train loss 1.80146. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.28it/s]\n",
      "epoch 556 iter 16: train loss 1.80143. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.95it/s]\n",
      "epoch 557 iter 16: train loss 1.80137. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 115.10it/s]\n",
      "epoch 558 iter 16: train loss 1.80155. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 131.55it/s]\n",
      "epoch 559 iter 16: train loss 1.80134. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.76it/s]\n",
      "epoch 560 iter 16: train loss 1.80218. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 126.56it/s]\n",
      "epoch 561 iter 16: train loss 1.80337. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.12it/s]\n",
      "epoch 562 iter 16: train loss 1.80147. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 140.67it/s]\n",
      "epoch 563 iter 16: train loss 1.80310. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 124.92it/s]\n",
      "epoch 564 iter 16: train loss 1.80190. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 148.61it/s]\n",
      "epoch 565 iter 16: train loss 1.80176. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.43it/s]\n",
      "epoch 566 iter 16: train loss 1.80165. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 114.95it/s]\n",
      "epoch 567 iter 16: train loss 1.80164. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.79it/s]\n",
      "epoch 568 iter 16: train loss 1.80171. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.61it/s]\n",
      "epoch 569 iter 16: train loss 1.80150. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.66it/s]\n",
      "epoch 570 iter 16: train loss 1.80166. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 80.98it/s] \n",
      "epoch 571 iter 16: train loss 1.80146. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.05it/s]\n",
      "epoch 572 iter 16: train loss 1.80162. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.15it/s]\n",
      "epoch 573 iter 16: train loss 1.80152. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 83.07it/s]\n",
      "epoch 574 iter 16: train loss 1.80167. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.61it/s]\n",
      "epoch 575 iter 16: train loss 1.80179. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 158.29it/s]\n",
      "epoch 576 iter 16: train loss 1.80212. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.62it/s]\n",
      "epoch 577 iter 16: train loss 1.80209. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.99it/s]\n",
      "epoch 578 iter 16: train loss 1.80448. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 168.33it/s]\n",
      "epoch 579 iter 16: train loss 1.80131. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.19it/s]\n",
      "epoch 580 iter 16: train loss 1.80313. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.64it/s]\n",
      "epoch 581 iter 16: train loss 1.80145. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 104.95it/s]\n",
      "epoch 582 iter 16: train loss 1.80288. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.92it/s]\n",
      "epoch 583 iter 16: train loss 1.80154. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 80.37it/s]\n",
      "epoch 584 iter 16: train loss 1.80301. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 95.42it/s]\n",
      "epoch 585 iter 16: train loss 1.80154. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.26it/s]\n",
      "epoch 586 iter 16: train loss 1.80324. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 125.91it/s]\n",
      "epoch 587 iter 16: train loss 1.80144. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.13it/s]\n",
      "epoch 588 iter 16: train loss 1.80335. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 81.59it/s]\n",
      "epoch 589 iter 16: train loss 1.80139. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 73.41it/s]\n",
      "epoch 590 iter 16: train loss 1.80334. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 80.71it/s]\n",
      "epoch 591 iter 16: train loss 1.80136. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.82it/s]\n",
      "epoch 592 iter 16: train loss 1.80332. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 90.19it/s]\n",
      "epoch 593 iter 16: train loss 1.80133. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 77.59it/s] \n",
      "epoch 594 iter 16: train loss 1.80333. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 93.38it/s] \n",
      "epoch 595 iter 16: train loss 1.80130. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 88.81it/s] \n",
      "epoch 596 iter 16: train loss 1.80336. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 88.57it/s]\n",
      "epoch 597 iter 16: train loss 1.80128. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 88.32it/s]\n",
      "epoch 598 iter 16: train loss 1.80339. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.93it/s]\n",
      "epoch 599 iter 16: train loss 1.80125. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 125.69it/s]\n",
      "epoch 600 iter 16: train loss 1.80342. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 124.62it/s]\n",
      "epoch 601 iter 16: train loss 1.80122. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 91.54it/s] \n",
      "epoch 602 iter 16: train loss 1.80345. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.35it/s]\n",
      "epoch 603 iter 16: train loss 1.80120. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.68it/s]\n",
      "epoch 604 iter 16: train loss 1.80348. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.77it/s]\n",
      "epoch 605 iter 16: train loss 1.80118. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.64it/s]\n",
      "epoch 606 iter 16: train loss 1.80351. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 104.41it/s]\n",
      "epoch 607 iter 16: train loss 1.80116. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 107.57it/s]\n",
      "epoch 608 iter 16: train loss 1.80354. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 79.31it/s]\n",
      "epoch 609 iter 16: train loss 1.80114. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.32it/s]\n",
      "epoch 610 iter 16: train loss 1.80357. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.21it/s]\n",
      "epoch 611 iter 16: train loss 1.80112. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.17it/s]\n",
      "epoch 612 iter 16: train loss 1.80359. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 98.48it/s] \n",
      "epoch 613 iter 16: train loss 1.80110. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 112.55it/s]\n",
      "epoch 614 iter 16: train loss 1.80361. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 104.52it/s]\n",
      "epoch 615 iter 16: train loss 1.80108. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 107.17it/s]\n",
      "epoch 616 iter 16: train loss 1.80364. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.79it/s]\n",
      "epoch 617 iter 16: train loss 1.80107. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 92.66it/s] \n",
      "epoch 618 iter 16: train loss 1.80365. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 130.46it/s]\n",
      "epoch 619 iter 16: train loss 1.80105. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 89.26it/s]\n",
      "epoch 620 iter 16: train loss 1.80367. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.74it/s]\n",
      "epoch 621 iter 16: train loss 1.80104. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.04it/s]\n",
      "epoch 622 iter 16: train loss 1.80368. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 84.03it/s] \n",
      "epoch 623 iter 16: train loss 1.80102. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 79.28it/s]\n",
      "epoch 624 iter 16: train loss 1.80369. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 94.23it/s]\n",
      "epoch 625 iter 16: train loss 1.80101. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 104.29it/s]\n",
      "epoch 626 iter 16: train loss 1.80370. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 85.69it/s] \n",
      "epoch 627 iter 16: train loss 1.80100. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.37it/s]\n",
      "epoch 628 iter 16: train loss 1.80370. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.85it/s]\n",
      "epoch 629 iter 16: train loss 1.80099. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.54it/s]\n",
      "epoch 630 iter 16: train loss 1.80371. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 87.70it/s]\n",
      "epoch 631 iter 16: train loss 1.80098. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.36it/s]\n",
      "epoch 632 iter 16: train loss 1.80371. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 97.88it/s] \n",
      "epoch 633 iter 16: train loss 1.80096. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 81.49it/s]\n",
      "epoch 634 iter 16: train loss 1.80369. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 121.88it/s]\n",
      "epoch 635 iter 16: train loss 1.80095. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.00it/s]\n",
      "epoch 636 iter 16: train loss 1.80364. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 107.33it/s]\n",
      "epoch 637 iter 16: train loss 1.80095. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.36it/s]\n",
      "epoch 638 iter 16: train loss 1.80364. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.84it/s]\n",
      "epoch 639 iter 16: train loss 1.80094. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.66it/s]\n",
      "epoch 640 iter 16: train loss 1.80364. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.44it/s]\n",
      "epoch 641 iter 16: train loss 1.80093. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 82.45it/s]\n",
      "epoch 642 iter 16: train loss 1.80361. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 129.32it/s]\n",
      "epoch 643 iter 16: train loss 1.80093. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 104.15it/s]\n",
      "epoch 644 iter 16: train loss 1.80362. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.44it/s]\n",
      "epoch 645 iter 16: train loss 1.80092. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 107.96it/s]\n",
      "epoch 646 iter 16: train loss 1.80363. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 94.66it/s]\n",
      "epoch 647 iter 16: train loss 1.80091. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 114.86it/s]\n",
      "epoch 648 iter 16: train loss 1.80359. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 100.21it/s]\n",
      "epoch 649 iter 16: train loss 1.80091. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 114.48it/s]\n",
      "epoch 650 iter 16: train loss 1.80360. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 141.54it/s]\n",
      "epoch 651 iter 16: train loss 1.80090. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.52it/s]\n",
      "epoch 652 iter 16: train loss 1.80360. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.28it/s]\n",
      "epoch 653 iter 16: train loss 1.80090. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.00it/s]\n",
      "epoch 654 iter 16: train loss 1.80356. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 95.29it/s]\n",
      "epoch 655 iter 16: train loss 1.80089. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 122.26it/s]\n",
      "epoch 656 iter 16: train loss 1.80356. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.72it/s]\n",
      "epoch 657 iter 16: train loss 1.80088. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.00it/s]\n",
      "epoch 658 iter 16: train loss 1.80355. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 129.62it/s]\n",
      "epoch 659 iter 16: train loss 1.80088. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 132.88it/s]\n",
      "epoch 660 iter 16: train loss 1.80351. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.68it/s]\n",
      "epoch 661 iter 16: train loss 1.80088. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.63it/s]\n",
      "epoch 662 iter 16: train loss 1.80350. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.35it/s]\n",
      "epoch 663 iter 16: train loss 1.80090. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 86.74it/s] \n",
      "epoch 664 iter 16: train loss 1.80356. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.39it/s]\n",
      "epoch 665 iter 16: train loss 1.80085. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 121.96it/s]\n",
      "epoch 666 iter 16: train loss 1.80346. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 92.14it/s]\n",
      "epoch 667 iter 16: train loss 1.80090. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.93it/s]\n",
      "epoch 668 iter 16: train loss 1.80347. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.92it/s]\n",
      "epoch 669 iter 16: train loss 1.80085. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 84.57it/s]\n",
      "epoch 670 iter 16: train loss 1.80340. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.16it/s]\n",
      "epoch 671 iter 16: train loss 1.80089. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 71.36it/s]\n",
      "epoch 672 iter 16: train loss 1.80338. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.15it/s]\n",
      "epoch 673 iter 16: train loss 1.80088. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 86.84it/s] \n",
      "epoch 674 iter 16: train loss 1.80337. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 55.44it/s]\n",
      "epoch 675 iter 16: train loss 1.80087. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 75.96it/s]\n",
      "epoch 676 iter 16: train loss 1.80333. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 62.52it/s]\n",
      "epoch 677 iter 16: train loss 1.80087. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 69.94it/s]\n",
      "epoch 678 iter 16: train loss 1.80329. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 61.56it/s]\n",
      "epoch 679 iter 16: train loss 1.80088. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 72.35it/s]\n",
      "epoch 680 iter 16: train loss 1.80323. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 83.35it/s]\n",
      "epoch 681 iter 16: train loss 1.80084. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 69.23it/s]\n",
      "epoch 682 iter 16: train loss 1.80312. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 92.18it/s]\n",
      "epoch 683 iter 16: train loss 1.80089. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.37it/s]\n",
      "epoch 684 iter 16: train loss 1.80307. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 89.29it/s] \n",
      "epoch 685 iter 16: train loss 1.80088. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 96.38it/s] \n",
      "epoch 686 iter 16: train loss 1.80304. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 104.53it/s]\n",
      "epoch 687 iter 16: train loss 1.80089. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.14it/s]\n",
      "epoch 688 iter 16: train loss 1.80298. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 76.00it/s]\n",
      "epoch 689 iter 16: train loss 1.80089. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.08it/s]\n",
      "epoch 690 iter 16: train loss 1.80292. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 76.45it/s]\n",
      "epoch 691 iter 16: train loss 1.80089. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 77.35it/s]\n",
      "epoch 692 iter 16: train loss 1.80284. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.18it/s]\n",
      "epoch 693 iter 16: train loss 1.80091. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.35it/s]\n",
      "epoch 694 iter 16: train loss 1.80280. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 107.51it/s]\n",
      "epoch 695 iter 16: train loss 1.80092. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 124.30it/s]\n",
      "epoch 696 iter 16: train loss 1.80345. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 104.84it/s]\n",
      "epoch 697 iter 16: train loss 1.80086. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.29it/s]\n",
      "epoch 698 iter 16: train loss 1.80291. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.99it/s]\n",
      "epoch 699 iter 16: train loss 1.80090. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 98.40it/s] \n",
      "epoch 700 iter 16: train loss 1.80273. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.43it/s]\n",
      "epoch 701 iter 16: train loss 1.80090. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 98.30it/s]\n",
      "epoch 702 iter 16: train loss 1.80258. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 83.65it/s] \n",
      "epoch 703 iter 16: train loss 1.80093. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.18it/s]\n",
      "epoch 704 iter 16: train loss 1.80314. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 95.48it/s] \n",
      "epoch 705 iter 16: train loss 1.80089. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 107.04it/s]\n",
      "epoch 706 iter 16: train loss 1.80268. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 85.27it/s]\n",
      "epoch 707 iter 16: train loss 1.80093. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.71it/s]\n",
      "epoch 708 iter 16: train loss 1.80249. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.19it/s]\n",
      "epoch 709 iter 16: train loss 1.80097. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.03it/s]\n",
      "epoch 710 iter 16: train loss 1.80233. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 114.68it/s]\n",
      "epoch 711 iter 16: train loss 1.80097. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.36it/s]\n",
      "epoch 712 iter 16: train loss 1.80283. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 112.49it/s]\n",
      "epoch 713 iter 16: train loss 1.80093. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.17it/s]\n",
      "epoch 714 iter 16: train loss 1.80236. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.65it/s]\n",
      "epoch 715 iter 16: train loss 1.80099. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 89.41it/s]\n",
      "epoch 716 iter 16: train loss 1.80280. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 85.31it/s] \n",
      "epoch 717 iter 16: train loss 1.80096. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 104.07it/s]\n",
      "epoch 718 iter 16: train loss 1.80239. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 97.80it/s] \n",
      "epoch 719 iter 16: train loss 1.80096. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 91.98it/s] \n",
      "epoch 720 iter 16: train loss 1.80259. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.73it/s]\n",
      "epoch 721 iter 16: train loss 1.80103. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.68it/s]\n",
      "epoch 722 iter 16: train loss 1.80187. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 95.43it/s] \n",
      "epoch 723 iter 16: train loss 1.80111. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.28it/s]\n",
      "epoch 724 iter 16: train loss 1.80160. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.48it/s]\n",
      "epoch 725 iter 16: train loss 1.80103. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.63it/s]\n",
      "epoch 726 iter 16: train loss 1.80188. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 97.41it/s] \n",
      "epoch 727 iter 16: train loss 1.80112. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 124.80it/s]\n",
      "epoch 728 iter 16: train loss 1.80203. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 80.69it/s] \n",
      "epoch 729 iter 16: train loss 1.80111. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 121.54it/s]\n",
      "epoch 730 iter 16: train loss 1.80141. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 121.31it/s]\n",
      "epoch 731 iter 16: train loss 1.80125. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 124.83it/s]\n",
      "epoch 732 iter 16: train loss 1.80163. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 88.26it/s]\n",
      "epoch 733 iter 16: train loss 1.80125. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 96.17it/s] \n",
      "epoch 734 iter 16: train loss 1.80122. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 115.51it/s]\n",
      "epoch 735 iter 16: train loss 1.80129. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 82.02it/s]\n",
      "epoch 736 iter 16: train loss 1.80110. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 114.66it/s]\n",
      "epoch 737 iter 16: train loss 1.80126. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.22it/s]\n",
      "epoch 738 iter 16: train loss 1.80101. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 138.47it/s]\n",
      "epoch 739 iter 16: train loss 1.80141. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 95.88it/s]\n",
      "epoch 740 iter 16: train loss 1.80119. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 87.48it/s]\n",
      "epoch 741 iter 16: train loss 1.80136. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.93it/s]\n",
      "epoch 742 iter 16: train loss 1.80056. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 93.14it/s]\n",
      "epoch 743 iter 16: train loss 1.80136. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.94it/s]\n",
      "epoch 744 iter 16: train loss 1.80118. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 96.37it/s] \n",
      "epoch 745 iter 16: train loss 1.80093. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 135.20it/s]\n",
      "epoch 746 iter 16: train loss 1.80201. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.35it/s]\n",
      "epoch 747 iter 16: train loss 1.80120. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 128.03it/s]\n",
      "epoch 748 iter 16: train loss 1.80118. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 91.15it/s]\n",
      "epoch 749 iter 16: train loss 1.80251. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 128.69it/s]\n",
      "epoch 750 iter 16: train loss 1.80103. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.59it/s]\n",
      "epoch 751 iter 16: train loss 1.80135. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 96.09it/s]\n",
      "epoch 752 iter 16: train loss 1.80242. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.36it/s]\n",
      "epoch 753 iter 16: train loss 1.80102. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.27it/s]\n",
      "epoch 754 iter 16: train loss 1.80122. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.81it/s]\n",
      "epoch 755 iter 16: train loss 1.80230. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 129.59it/s]\n",
      "epoch 756 iter 16: train loss 1.80108. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.53it/s]\n",
      "epoch 757 iter 16: train loss 1.80303. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 87.12it/s] \n",
      "epoch 758 iter 16: train loss 1.80115. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.02it/s]\n",
      "epoch 759 iter 16: train loss 1.80093. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 100.58it/s]\n",
      "epoch 760 iter 16: train loss 1.80154. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 66.50it/s]\n",
      "epoch 761 iter 16: train loss 1.80085. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 98.89it/s] \n",
      "epoch 762 iter 16: train loss 1.80103. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 84.31it/s]\n",
      "epoch 763 iter 16: train loss 1.80074. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 80.95it/s]\n",
      "epoch 764 iter 16: train loss 1.80123. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.08it/s]\n",
      "epoch 765 iter 16: train loss 1.80110. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 73.16it/s]\n",
      "epoch 766 iter 16: train loss 1.80082. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.99it/s]\n",
      "epoch 767 iter 16: train loss 1.80149. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 87.57it/s]\n",
      "epoch 768 iter 16: train loss 1.80109. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 104.65it/s]\n",
      "epoch 769 iter 16: train loss 1.80073. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 126.88it/s]\n",
      "epoch 770 iter 16: train loss 1.80211. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 99.63it/s]\n",
      "epoch 771 iter 16: train loss 1.80131. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.10it/s]\n",
      "epoch 772 iter 16: train loss 1.80140. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 94.18it/s] \n",
      "epoch 773 iter 16: train loss 1.80225. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 97.90it/s]\n",
      "epoch 774 iter 16: train loss 1.80100. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 84.24it/s] \n",
      "epoch 775 iter 16: train loss 1.80143. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.38it/s]\n",
      "epoch 776 iter 16: train loss 1.80234. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.55it/s]\n",
      "epoch 777 iter 16: train loss 1.80092. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 130.31it/s]\n",
      "epoch 778 iter 16: train loss 1.80237. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 100.14it/s]\n",
      "epoch 779 iter 16: train loss 1.80129. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 95.93it/s] \n",
      "epoch 780 iter 16: train loss 1.80078. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.88it/s]\n",
      "epoch 781 iter 16: train loss 1.80106. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 80.93it/s] \n",
      "epoch 782 iter 16: train loss 1.80075. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.39it/s]\n",
      "epoch 783 iter 16: train loss 1.80095. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 94.40it/s]\n",
      "epoch 784 iter 16: train loss 1.80103. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.15it/s]\n",
      "epoch 785 iter 16: train loss 1.80069. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 89.76it/s]\n",
      "epoch 786 iter 16: train loss 1.80085. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.27it/s]\n",
      "epoch 787 iter 16: train loss 1.80107. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 84.13it/s] \n",
      "epoch 788 iter 16: train loss 1.80110. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 97.17it/s] \n",
      "epoch 789 iter 16: train loss 1.80085. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 89.49it/s] \n",
      "epoch 790 iter 16: train loss 1.80071. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.61it/s]\n",
      "epoch 791 iter 16: train loss 1.80120. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 112.43it/s]\n",
      "epoch 792 iter 16: train loss 1.80104. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 132.55it/s]\n",
      "epoch 793 iter 16: train loss 1.80077. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.13it/s]\n",
      "epoch 794 iter 16: train loss 1.80172. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.82it/s]\n",
      "epoch 795 iter 16: train loss 1.80115. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 133.60it/s]\n",
      "epoch 796 iter 16: train loss 1.80068. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 107.85it/s]\n",
      "epoch 797 iter 16: train loss 1.80083. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 98.34it/s] \n",
      "epoch 798 iter 16: train loss 1.80160. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 96.17it/s]\n",
      "epoch 799 iter 16: train loss 1.80111. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.94it/s]\n",
      "epoch 800 iter 16: train loss 1.80134. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 128.70it/s]\n",
      "epoch 801 iter 16: train loss 1.80226. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 78.36it/s]\n",
      "epoch 802 iter 16: train loss 1.80115. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.40it/s]\n",
      "epoch 803 iter 16: train loss 1.80305. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 122.45it/s]\n",
      "epoch 804 iter 16: train loss 1.80118. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.30it/s]\n",
      "epoch 805 iter 16: train loss 1.80075. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 115.13it/s]\n",
      "epoch 806 iter 16: train loss 1.80121. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 100.45it/s]\n",
      "epoch 807 iter 16: train loss 1.80087. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.63it/s]\n",
      "epoch 808 iter 16: train loss 1.80057. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 135.52it/s]\n",
      "epoch 809 iter 16: train loss 1.80109. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 125.43it/s]\n",
      "epoch 810 iter 16: train loss 1.80090. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 93.73it/s]\n",
      "epoch 811 iter 16: train loss 1.80086. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.82it/s]\n",
      "epoch 812 iter 16: train loss 1.80070. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.43it/s]\n",
      "epoch 813 iter 16: train loss 1.80096. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.24it/s]\n",
      "epoch 814 iter 16: train loss 1.80098. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 100.76it/s]\n",
      "epoch 815 iter 16: train loss 1.80092. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.56it/s]\n",
      "epoch 816 iter 16: train loss 1.80060. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 124.41it/s]\n",
      "epoch 817 iter 16: train loss 1.80110. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.43it/s]\n",
      "epoch 818 iter 16: train loss 1.80130. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 115.51it/s]\n",
      "epoch 819 iter 16: train loss 1.80104. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.83it/s]\n",
      "epoch 820 iter 16: train loss 1.80052. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.75it/s]\n",
      "epoch 821 iter 16: train loss 1.80112. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.38it/s]\n",
      "epoch 822 iter 16: train loss 1.80093. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 81.94it/s]\n",
      "epoch 823 iter 16: train loss 1.80099. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 81.62it/s]\n",
      "epoch 824 iter 16: train loss 1.80054. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 97.67it/s]\n",
      "epoch 825 iter 16: train loss 1.80085. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.21it/s]\n",
      "epoch 826 iter 16: train loss 1.80109. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.89it/s]\n",
      "epoch 827 iter 16: train loss 1.80107. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 104.32it/s]\n",
      "epoch 828 iter 16: train loss 1.80051. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.03it/s]\n",
      "epoch 829 iter 16: train loss 1.80086. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.86it/s]\n",
      "epoch 830 iter 16: train loss 1.80113. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.61it/s]\n",
      "epoch 831 iter 16: train loss 1.80100. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.00it/s]\n",
      "epoch 832 iter 16: train loss 1.80054. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 93.75it/s] \n",
      "epoch 833 iter 16: train loss 1.80088. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 112.78it/s]\n",
      "epoch 834 iter 16: train loss 1.80111. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.05it/s]\n",
      "epoch 835 iter 16: train loss 1.80103. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.39it/s]\n",
      "epoch 836 iter 16: train loss 1.80048. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.57it/s]\n",
      "epoch 837 iter 16: train loss 1.80089. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.42it/s]\n",
      "epoch 838 iter 16: train loss 1.80115. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 92.98it/s]\n",
      "epoch 839 iter 16: train loss 1.80105. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.34it/s]\n",
      "epoch 840 iter 16: train loss 1.80047. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.37it/s]\n",
      "epoch 841 iter 16: train loss 1.80115. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.48it/s]\n",
      "epoch 842 iter 16: train loss 1.80123. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.41it/s]\n",
      "epoch 843 iter 16: train loss 1.80101. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 107.74it/s]\n",
      "epoch 844 iter 16: train loss 1.80043. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 107.39it/s]\n",
      "epoch 845 iter 16: train loss 1.80131. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.32it/s]\n",
      "epoch 846 iter 16: train loss 1.80104. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 94.99it/s]\n",
      "epoch 847 iter 16: train loss 1.80093. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 100.48it/s]\n",
      "epoch 848 iter 16: train loss 1.80043. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 107.52it/s]\n",
      "epoch 849 iter 16: train loss 1.80120. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 114.67it/s]\n",
      "epoch 850 iter 16: train loss 1.80122. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 80.91it/s]\n",
      "epoch 851 iter 16: train loss 1.80095. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 125.79it/s]\n",
      "epoch 852 iter 16: train loss 1.80039. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.69it/s]\n",
      "epoch 853 iter 16: train loss 1.80125. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.09it/s]\n",
      "epoch 854 iter 16: train loss 1.80109. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 100.61it/s]\n",
      "epoch 855 iter 16: train loss 1.80092. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 100.76it/s]\n",
      "epoch 856 iter 16: train loss 1.80041. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 127.34it/s]\n",
      "epoch 857 iter 16: train loss 1.80116. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.45it/s]\n",
      "epoch 858 iter 16: train loss 1.80115. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 121.94it/s]\n",
      "epoch 859 iter 16: train loss 1.80084. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.40it/s]\n",
      "epoch 860 iter 16: train loss 1.80041. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.62it/s]\n",
      "epoch 861 iter 16: train loss 1.80088. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 107.98it/s]\n",
      "epoch 862 iter 16: train loss 1.80112. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 90.65it/s]\n",
      "epoch 863 iter 16: train loss 1.80090. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 88.85it/s]\n",
      "epoch 864 iter 16: train loss 1.80040. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.12it/s]\n",
      "epoch 865 iter 16: train loss 1.80106. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.47it/s]\n",
      "epoch 866 iter 16: train loss 1.80133. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.51it/s]\n",
      "epoch 867 iter 16: train loss 1.80095. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 114.07it/s]\n",
      "epoch 868 iter 16: train loss 1.80034. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.35it/s]\n",
      "epoch 869 iter 16: train loss 1.80122. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.31it/s]\n",
      "epoch 870 iter 16: train loss 1.80103. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 94.09it/s]\n",
      "epoch 871 iter 16: train loss 1.80083. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 138.57it/s]\n",
      "epoch 872 iter 16: train loss 1.80038. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.38it/s]\n",
      "epoch 873 iter 16: train loss 1.80104. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 96.47it/s]\n",
      "epoch 874 iter 16: train loss 1.80131. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 96.36it/s]\n",
      "epoch 875 iter 16: train loss 1.80081. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.47it/s]\n",
      "epoch 876 iter 16: train loss 1.80034. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.67it/s]\n",
      "epoch 877 iter 16: train loss 1.80084. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.62it/s]\n",
      "epoch 878 iter 16: train loss 1.80113. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 121.70it/s]\n",
      "epoch 879 iter 16: train loss 1.80086. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 99.88it/s] \n",
      "epoch 880 iter 16: train loss 1.80035. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 90.62it/s]\n",
      "epoch 881 iter 16: train loss 1.80101. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 77.41it/s]\n",
      "epoch 882 iter 16: train loss 1.80140. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 74.95it/s]\n",
      "epoch 883 iter 16: train loss 1.80089. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.95it/s]\n",
      "epoch 884 iter 16: train loss 1.80027. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 94.63it/s]\n",
      "epoch 885 iter 16: train loss 1.80119. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 93.32it/s]\n",
      "epoch 886 iter 16: train loss 1.80114. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 92.93it/s] \n",
      "epoch 887 iter 16: train loss 1.80079. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.00it/s]\n",
      "epoch 888 iter 16: train loss 1.80026. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 74.82it/s]\n",
      "epoch 889 iter 16: train loss 1.80143. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 97.85it/s] \n",
      "epoch 890 iter 16: train loss 1.80151. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 126.23it/s]\n",
      "epoch 891 iter 16: train loss 1.80081. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.78it/s]\n",
      "epoch 892 iter 16: train loss 1.80023. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 121.28it/s]\n",
      "epoch 893 iter 16: train loss 1.80079. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.39it/s]\n",
      "epoch 894 iter 16: train loss 1.80155. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 127.89it/s]\n",
      "epoch 895 iter 16: train loss 1.80072. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.96it/s]\n",
      "epoch 896 iter 16: train loss 1.80023. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.53it/s]\n",
      "epoch 897 iter 16: train loss 1.80082. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 98.33it/s] \n",
      "epoch 898 iter 16: train loss 1.80088. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 83.44it/s]\n",
      "epoch 899 iter 16: train loss 1.80070. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.25it/s]\n",
      "epoch 900 iter 16: train loss 1.80031. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.20it/s]\n",
      "epoch 901 iter 16: train loss 1.80076. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 122.41it/s]\n",
      "epoch 902 iter 16: train loss 1.80141. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 107.17it/s]\n",
      "epoch 903 iter 16: train loss 1.80077. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 93.76it/s] \n",
      "epoch 904 iter 16: train loss 1.80025. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 96.49it/s]\n",
      "epoch 905 iter 16: train loss 1.80100. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 107.63it/s]\n",
      "epoch 906 iter 16: train loss 1.80115. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 103.06it/s]\n",
      "epoch 907 iter 16: train loss 1.80071. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 115.29it/s]\n",
      "epoch 908 iter 16: train loss 1.80027. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.55it/s]\n",
      "epoch 909 iter 16: train loss 1.80091. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 95.94it/s]\n",
      "epoch 910 iter 16: train loss 1.80139. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.49it/s]\n",
      "epoch 911 iter 16: train loss 1.80073. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 97.01it/s] \n",
      "epoch 912 iter 16: train loss 1.80024. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 138.58it/s]\n",
      "epoch 913 iter 16: train loss 1.80096. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.91it/s]\n",
      "epoch 914 iter 16: train loss 1.80118. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 96.10it/s] \n",
      "epoch 915 iter 16: train loss 1.80068. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 96.54it/s]\n",
      "epoch 916 iter 16: train loss 1.80026. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.16it/s]\n",
      "epoch 917 iter 16: train loss 1.80088. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 97.40it/s]\n",
      "epoch 918 iter 16: train loss 1.80144. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 130.74it/s]\n",
      "epoch 919 iter 16: train loss 1.80070. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.70it/s]\n",
      "epoch 920 iter 16: train loss 1.80022. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 99.06it/s] \n",
      "epoch 921 iter 16: train loss 1.80094. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 114.71it/s]\n",
      "epoch 922 iter 16: train loss 1.80116. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 101.43it/s]\n",
      "epoch 923 iter 16: train loss 1.80065. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.41it/s]\n",
      "epoch 924 iter 16: train loss 1.80026. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.40it/s]\n",
      "epoch 925 iter 16: train loss 1.80084. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 89.44it/s]\n",
      "epoch 926 iter 16: train loss 1.80150. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 100.33it/s]\n",
      "epoch 927 iter 16: train loss 1.80067. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 128.75it/s]\n",
      "epoch 928 iter 16: train loss 1.80021. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 96.19it/s]\n",
      "epoch 929 iter 16: train loss 1.80090. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 126.04it/s]\n",
      "epoch 930 iter 16: train loss 1.80116. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 88.24it/s]\n",
      "epoch 931 iter 16: train loss 1.80059. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.71it/s]\n",
      "epoch 932 iter 16: train loss 1.80026. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 108.14it/s]\n",
      "epoch 933 iter 16: train loss 1.80082. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 97.27it/s] \n",
      "epoch 934 iter 16: train loss 1.80158. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 123.41it/s]\n",
      "epoch 935 iter 16: train loss 1.80068. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.45it/s]\n",
      "epoch 936 iter 16: train loss 1.80017. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 128.60it/s]\n",
      "epoch 937 iter 16: train loss 1.80096. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 119.72it/s]\n",
      "epoch 938 iter 16: train loss 1.80101. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 93.96it/s]\n",
      "epoch 939 iter 16: train loss 1.80063. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 109.83it/s]\n",
      "epoch 940 iter 16: train loss 1.80020. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 97.54it/s] \n",
      "epoch 941 iter 16: train loss 1.80072. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.65it/s]\n",
      "epoch 942 iter 16: train loss 1.80163. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 86.97it/s]\n",
      "epoch 943 iter 16: train loss 1.80070. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 71.53it/s]\n",
      "epoch 944 iter 16: train loss 1.80012. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 110.68it/s]\n",
      "epoch 945 iter 16: train loss 1.80074. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 100.31it/s]\n",
      "epoch 946 iter 16: train loss 1.80086. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 72.16it/s]\n",
      "epoch 947 iter 16: train loss 1.80057. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 77.99it/s]\n",
      "epoch 948 iter 16: train loss 1.80024. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 93.73it/s]\n",
      "epoch 949 iter 16: train loss 1.80065. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 47.92it/s]\n",
      "epoch 950 iter 16: train loss 1.80165. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 56.02it/s]\n",
      "epoch 951 iter 16: train loss 1.80074. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 81.39it/s]\n",
      "epoch 952 iter 16: train loss 1.80011. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 57.37it/s]\n",
      "epoch 953 iter 16: train loss 1.80080. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 74.63it/s] \n",
      "epoch 954 iter 16: train loss 1.80081. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 78.91it/s]\n",
      "epoch 955 iter 16: train loss 1.80055. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 73.79it/s] \n",
      "epoch 956 iter 16: train loss 1.80027. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 90.01it/s]\n",
      "epoch 957 iter 16: train loss 1.80066. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 70.20it/s]\n",
      "epoch 958 iter 16: train loss 1.80168. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 81.83it/s]\n",
      "epoch 959 iter 16: train loss 1.80078. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 74.02it/s]\n",
      "epoch 960 iter 16: train loss 1.80010. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 89.52it/s]\n",
      "epoch 961 iter 16: train loss 1.80130. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 67.46it/s]\n",
      "epoch 962 iter 16: train loss 1.80062. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.39it/s]\n",
      "epoch 963 iter 16: train loss 1.80063. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.54it/s]\n",
      "epoch 964 iter 16: train loss 1.80015. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 62.02it/s]\n",
      "epoch 965 iter 16: train loss 1.80074. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 88.27it/s]\n",
      "epoch 966 iter 16: train loss 1.80166. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 99.20it/s]\n",
      "epoch 967 iter 16: train loss 1.80074. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 86.10it/s] \n",
      "epoch 968 iter 16: train loss 1.80006. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 88.98it/s]\n",
      "epoch 969 iter 16: train loss 1.80095. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 106.10it/s]\n",
      "epoch 970 iter 16: train loss 1.80066. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 92.99it/s]\n",
      "epoch 971 iter 16: train loss 1.80054. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 84.09it/s]\n",
      "epoch 972 iter 16: train loss 1.80020. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 86.64it/s]\n",
      "epoch 973 iter 16: train loss 1.80067. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 79.22it/s] \n",
      "epoch 974 iter 16: train loss 1.80165. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.23it/s]\n",
      "epoch 975 iter 16: train loss 1.80075. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.46it/s]\n",
      "epoch 976 iter 16: train loss 1.80005. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 116.30it/s]\n",
      "epoch 977 iter 16: train loss 1.80117. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 99.69it/s]\n",
      "epoch 978 iter 16: train loss 1.80070. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.50it/s]\n",
      "epoch 979 iter 16: train loss 1.80055. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 98.94it/s]\n",
      "epoch 980 iter 16: train loss 1.80015. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 93.24it/s]\n",
      "epoch 981 iter 16: train loss 1.80077. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 112.25it/s]\n",
      "epoch 982 iter 16: train loss 1.80163. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 105.92it/s]\n",
      "epoch 983 iter 16: train loss 1.80078. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.54it/s]\n",
      "epoch 984 iter 16: train loss 1.80003. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 118.72it/s]\n",
      "epoch 985 iter 16: train loss 1.80124. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 91.61it/s] \n",
      "epoch 986 iter 16: train loss 1.80046. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 85.99it/s]\n",
      "epoch 987 iter 16: train loss 1.80051. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.87it/s]\n",
      "epoch 988 iter 16: train loss 1.80014. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 111.42it/s]\n",
      "epoch 989 iter 16: train loss 1.80058. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 117.37it/s]\n",
      "epoch 990 iter 16: train loss 1.80159. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 112.20it/s]\n",
      "epoch 991 iter 16: train loss 1.80062. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 99.18it/s]\n",
      "epoch 992 iter 16: train loss 1.80006. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 82.07it/s]\n",
      "epoch 993 iter 16: train loss 1.80077. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 102.38it/s]\n",
      "epoch 994 iter 16: train loss 1.80117. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 125.60it/s]\n",
      "epoch 995 iter 16: train loss 1.80049. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 112.54it/s]\n",
      "epoch 996 iter 16: train loss 1.80014. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 113.66it/s]\n",
      "epoch 997 iter 16: train loss 1.80080. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 91.29it/s]\n",
      "epoch 998 iter 16: train loss 1.80158. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 120.31it/s]\n",
      "epoch 999 iter 16: train loss 1.80071. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 139.16it/s]\n",
      "epoch 1000 iter 16: train loss 1.79998. lr 8.000000e-03: 100%|██████████| 17/17 [00:00<00:00, 97.89it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anarion/anaconda3/envs/local_nmt/lib/python3.8/site-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([528, 11])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "correct_count = 0\n",
    "predict, _ = model(\n",
    "    torch.tensor(data=test_df.drop('quality', axis=1).to_numpy(), dtype=torch.float),\n",
    "    torch.tensor(data=test_df['quality'].to_numpy(), dtype=torch.long)\n",
    ")\n",
    "predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5871)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.eq(torch.argmax(predict, dim=1), torch.tensor(test_df['quality'].to_numpy()))) / len(test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('local_nmt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a052ce33554942f407f69a23501ea544d79230aa69d3d877b26efa761dce54b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
